# vim: syntax=python

# >6.0 is required for modules
from snakemake.utils import min_version
min_version("6.0")

import itertools
import yaml
import pandas as pd


# Exhaustive list of interesting comparisons for PTA, MDA, batch and pass vs. rescue
'''
config['all_comparisons'] = [
     'pta_neuron___A_vs_pta_oligo___A',
     'pta_neuron___AB_vs_pta_oligo___AB',
     'pta_neuron___A_vs_pta_oligo_batch1___A', 'pta_neuron___A_vs_pta_oligo_batch2___A',
     'pta_neuron___AB_vs_pta_oligo_batch1___AB', 'pta_neuron___AB_vs_pta_oligo_batch2___AB',
     'pta_oligo_batch1___A_vs_pta_oligo_batch2___A',
     'pta_oligo_batch1___AB_vs_pta_oligo_batch2___AB',
     'pta_oligo_A_vs_mda_sox10_infant___A', 'pta_oligo_A_vs_mda_sox10_elderly___A',
     'mda_sox10_infant___A_vs_mda_sox10_elderly___A',
     'mda_gfap_infant___A_vs_mda_gfap_elderly___A',
     'mda_sox10_elderly___A_vs_mda_gfap_elderly___A',
     'pta_oligo___A_vs_mda_gfap_infant___A', 'pta_oligo___A_vs_mda_gfap_elderly___A' ]
'''
'''
# What is going on here? Why are these doubled up?
config['all_comparisons'] = [
     'pta_neuron_vs_pta_oligo',
     'pta_neuron_vs_pta_oligo',
     'pta_neuron_vs_pta_oligo_batch1', 'pta_neuron_vs_pta_oligo_batch2',
     'pta_neuron_vs_pta_oligo_batch1', 'pta_neuron_vs_pta_oligo_batch2',
     'pta_oligo_batch1_vs_pta_oligo_batch2',
     'pta_oligo_batch1_vs_pta_oligo_batch2',
     'pta_oligo_vs_mda_sox10_infant', 'pta_oligo_vs_mda_sox10_elderly',
     'mda_sox10_infant_vs_mda_sox10_elderly',
     'mda_gfap_infant_vs_mda_gfap_elderly',
     'mda_sox10_elderly_vs_mda_gfap_elderly',
     'pta_oligo_vs_mda_gfap_infant', 'pta_oligo_vs_mda_gfap_elderly' ]
'''

config['all_comparisons'] = [
     'pta_neuron_vs_pta_oligo',
     'pta_neuron_vs_pta_oligo_batch1', 'pta_neuron_vs_pta_oligo_batch2',
     'pta_oligo_batch1_vs_pta_oligo_batch2',
     'pta_oligo_vs_mda_sox10_infant', 'pta_oligo_vs_mda_sox10_elderly',
     'mda_sox10_infant_vs_mda_sox10_elderly',
     'mda_gfap_infant_vs_mda_gfap_elderly',
     'mda_sox10_elderly_vs_mda_gfap_elderly',
     'pta_oligo_vs_mda_gfap_infant', 'pta_oligo_vs_mda_gfap_elderly' ]


# Just the major groups of pta_neuron, pta_oligo, mda_sox10 and mda_gfap
config['rescue_group_comparisons'] = [
     'pta_neuron_vs_pta_oligo',
     'pta_oligo_vs_mda_sox10',
     'mda_sox10_vs_mda_gfap',
     'pta_oligo_vs_mda_gfap' ]


# Order matters
#config['comparison_groups'] = [ 'pta_neuron', 'pta_oligo', 'pta_oligo_batch1', 'pta_oligo_batch2', 'mda_sox10_infant', 'mda_sox10_elderly', 'mda_gfap_infant', 'mda_gfap_elderly' ]
config['comparison_groups'] = [ 'pta_neuron_half1', 'pta_neuron_half2', 'pta_neuron', 'pta_oligo_half1', 'pta_oligo_half2', 'pta_oligo', 'pta_oligo_batch1', 'mda_sox10_elderly', 'mda_gfap_elderly' ]


# Autosomes only
config['chrs_to_analyze'] = [ str(x) for x in range(1, 23) ]

# Important note on the `config' dictionary: consolidate all global variables so
# they can be robustly passed to module calls.
config['metadata'] = pd.read_csv('metadata/sample_metadata.csv')
meta = config['metadata']  # Just for convenience within this Snakefile

ageclasses = set(meta['ageclass'])

# For subsampling analysis in response to reviewers.
#
# Ideally assignment to half1 or half2 would be in the metadata file, but changing
# that reruns the whole pipeline. So instead, just record the assignments here.
neuron_half1 = [ "1278BA9-B", "1278BA9-C", "5817PFC-B", "5871-Neuron-4", "5871-Neuron-5",
    "1465BA9-B", "1465BA9-C", "5559PFC-A", "5559PFC-B", "5559PFC-C", "4643-Neuron-4",
    "4643-Neuron-6", "5087PFC-A", "5087PFC-B", "936PFC-A", "5219-Neuron-4", "5657PFC-A",
    "5657PFC-B", "5657PFC-C", "5823PFC-A", "5823PFC-B", "5823PFC-C", "UMB4976_E2",
    "UMB4976_E3", "UMB5451_B5", "UMB5943_C2", "UMB5943_C5" ]
neuron_half2 = [ "1278BA9-A", "5817PFC-A", "5817PFC-C", "5871-Neuron-6", "4638-Neuron-5",
    "4638-Neuron-6", "1465BA9-A", "1465BA9-D", "4643-Neuron-3", "5087PFC-C", "936PFC-B",
    "936PFC-C", "5219-Neuron-2", "5219-Neuron-5", "UMB4976_E1", "UMB5451_B2", "UMB5451_B3",
    "UMB5572_D2", "UMB5572_D3", "UMB5572_D4", "UMB5666_F1", "UMB5666_F2", "UMB5666_F5",
    "UMB5943_C4" ]
oligo_half1 = [ "1278-Oligo-5", "1278-Oligo-7", "1278-Oligo-8", "5817-Oligo-6",
    "5871-Oligo-7", "4638-Oligo-5", "1465-Oligo-5", "1465-Oligo-8", "5559-Oligo-5",
    "4643-Oligo-8", "5087-Oligo-4", "5087-Oligo-7", "5219-Oligo-7", "5657-Oligo-3",
    "5657-Oligo-5", "5657-Oligo-7", "5823-Oligo-8" ]
oligo_half2 = [ "5817-Oligo-4", "5817-Oligo-7", "5871-Oligo-4", "5871-Oligo-5",
    "4638-Oligo-4", "1465-Oligo-7", "5559-Oligo-3", "5559-Oligo-8", "4643-Oligo-5",
    "4643-Oligo-6", "5219-Oligo-5", "5219-Oligo-6", "5823-Oligo-6", "5823-Oligo-7" ]

meta['half'] = 0
for sample_name in neuron_half1 + oligo_half1:
    meta.loc[meta['sample'] == sample_name, 'half'] = 1
for sample_name in neuron_half2 + oligo_half2:
    meta.loc[meta['sample'] == sample_name, 'half'] = 2

with open('metadata/bams.yaml') as yf:
    bams = yaml.load(yf, Loader=yaml.FullLoader)
config['bams'] = bams

# `bams` is a dict mapping donor ID -> list(single cell bams, bulk bams, other bams), where
# each of the elements in the above list are also dicts mapping sample ID -> bam path.
# For convenience, flatten `bams` into just a list of file paths with no related metadata.
config['all_samples'] = sum([ list(bams[k][bt].keys()) for k in bams.keys() for bt in bams[k].keys()  ], [])

# Just single cell samples
config['all_single_cells'] = sum([ list(bams[k]['single_cell'].keys()) for k in bams.keys() ], [])

# Same as above, but instead of a flat list of sample names, flat list of BAM paths
config['all_bams'] = sum([ list(bams[k][bt].values()) for k in bams.keys() for bt in bams[k].keys()  ], [])

config['all_donors'] = list(bams.keys())

config['sample_to_donor_map'] = dict((sample, donor) for donor in bams.keys() \
    for sample in list(bams[donor]['single_cell'].keys()) + list(bams[donor]['bulk'].keys()) )

config['scan2_depth_matrices'] = dict((donor, "scan2/" + donor + "/scan2/depth_profile/joint_depth_matrix.tab.gz") for donor in config['all_donors'])

config['muttype_to_passtype'] = {
    'pta': {
        'snv': 'AB',
        'indel': 'indel_AB'
    },
    'mda': {
        'snv': 'A',
        'indel': 'indel_A'
    }
}

# Read in the input manifest
#manifest = pd.read_csv('manifests/INPUT_MANIFEST', sep='\t',comment='#')
#qualtypes = set(manifest['qualtype'])

# Coarse high-level groups that are constantly reused.
generic_groups = [ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap', 'pta_oligo_batch1', 'pta_oligo_batch2' ]


# All of these groups *should* be recognized in the group_from_meta() function below.
all_groups = [ 'pta_neuron', 'pta_oligo', 'pta_oligo_batch1', 'pta_oligo_batch2', 'mda_sox10', 'mda_sox10_infant', 'mda_sox10_elderly', 'mda_gfap', 'mda_gfap_infant', 'mda_gfap_elderly', 'pta_neuron_infant', 'pta_oligo_infant', 'pta_neuron_half1', 'pta_neuron_half2', 'pta_oligo_half1', 'pta_oligo_half2' ]
config['all_groups'] = all_groups



# Convenience function to recognize a few constantly used grouping criteria. Expect
# more to be added. Should probably recognize everything listed in `generic_groups`.
# 
# Colors here override colors specified in sample_metadata.csv. Note that these
# groups are not disjoint, so the single color specified in the metadata would not
# work here. However, try to use the indicated color when possible.
def group_from_meta(group, return_color=False):
    if group == 'pta_neuron':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'neuron')]
        color = list(subset['color'])[0] # 'black'
        color = '#323232'  # not-quite-black. overriding the metadata
    elif group == 'pta_neuron_infant':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'neuron') & (meta['ageclass'] == 'infant')]
        color = list(subset['color'])[0] # 'black'
        color = '#323232'  # not-quite-black. overriding the metadata
    elif group == 'pta_neuron_half1':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'neuron') & (meta['half'] == 1)]
        color = list(subset['color'])[0] # 'black'
        color = '#888888'  # not-quite-black. overriding the metadata
    elif group == 'pta_neuron_half2':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'neuron') & (meta['half'] == 2)]
        color = list(subset['color'])[0] # 'black'
        color = '#cccccc'  # not-quite-black. overriding the metadata
    elif group == 'pta_oligo':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo')]
        color = list(subset['color'])[0] # '#DE556E'
    elif group == 'pta_oligo_infant':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo') & (meta['ageclass'] == 'infant')]
        color = list(subset['color'])[0] # '#DE556E'
    elif group == 'pta_oligo_half1':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo') & (meta['half'] == 1)]
        color = 'darkred' # list(subset['color'])[0]
    elif group == 'pta_oligo_half2':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo') & (meta['half'] == 2)]
        color = 'maroon' # list(subset['color'])[0]
    elif group == 'pta_oligo_batch1':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo') & (meta['batch'] == 1)]
        color = '#c994c7' # 'violetred'  # violetred{,1} were not distinguishable enough
    elif group == 'pta_oligo_batch2':
        subset = meta[(meta['amp'] == 'PTA') & (meta['type'] == 'oligo') & (meta['batch'] == 2)]
        color = '#e7298a' # 'violetred1'
    elif group == 'mda_sox10':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'SOX10')]
        color = list(subset['color'])[0] # 'orange'
    elif group == 'mda_sox10_infant':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'SOX10') & (meta['ageclass'] == 'infant')]
        color = 'grey50'
    elif group == 'mda_sox10_elderly':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'SOX10') & (meta['ageclass'] == 'elderly')]
        color = list(subset['color'])[0] # 'orange'
    elif group == 'mda_gfap':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'GFAP')]
        color = list(subset['color'])[0] # 'purple'
    elif group == 'mda_gfap_infant':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'GFAP') & (meta['ageclass'] == 'infant')]
        color = 'grey35'
    elif group == 'mda_gfap_elderly':
        subset = meta[(meta['amp'] == 'MDA') & (meta['selection'] == 'GFAP') & (meta['ageclass'] == 'elderly')]
        color = list(subset['color'])[0] # 'purple'
    else:
        raise RuntimeError('unrecognized group "' + group + '"')

    if return_color:
        return(color)
    else:
        return(subset)

config['any_group_to_samples'] = dict([ (g, group_from_meta(g)['sample']) for g in all_groups ])

config['all_pta_cells'] = list(group_from_meta('pta_neuron')['sample']) + list(group_from_meta('pta_oligo')['sample'])

config['group_colors'] = dict([ (g, group_from_meta(g, return_color=True)) for g in all_groups ])


# Run mutation signature-based rescue on cells grouped as follows:
#    1. All PTA-amplified neurons (nearly identical to Luquette et al 2022, except more neurons now).
#    2. All PTA-amplified SOX10-sorted oligodendrocytes
#    3. All MDA-amplified SOX10-sorted oligodendrocytes
#    4. All MDA-amplified GFAP-sorted oligodendrocytes.
# Note SCAN2 signature rescue is NOT DESIGNED for MDA amplified single cells.  After
# doing steps (3) and (4) above, the rescued calls are ignored.  They are run through
# the rescue pipeline just for the sake of uniform outputs.
scan2_rescue_groups = [ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap' ]

def rescue_group_to_scan2_objects(rescue_group):
    subset = group_from_meta(rescue_group)
    return(dict(zip(
            list('scan2/' + subset['donor'] + '/scan2/sensitivity/' + subset['sample'] + '/scan2_object.rda'),
            list(subset['sample'])
        )))

config['scan2_rescue_groups'] = dict((g, rescue_group_to_scan2_objects(g)) for g in scan2_rescue_groups)
config['scan2_rescue_groups_reverse'] = \
    dict((sample, g) for g in scan2_rescue_groups for sample in rescue_group_to_scan2_objects(g).values())

synthetic_groups = \
    [ 'pta_neuron_half1', 'pta_neuron_half2', 'pta_oligo_half1', 'pta_oligo_half2' ] +  \
    [ 'pta_oligo_batch1', 'pta_oligo_batch2' ] + \
    expand("mda_{selection}_{ageclass}",
        selection=[ 'gfap', 'sox10' ], ageclass=[ 'infant', 'elderly' ])
config['synthetic_groups'] = dict((g, list(group_from_meta(g)['sample'])) for g in synthetic_groups)


def aging_group_to_scan2_objects(aging_group):
    subset = group_from_meta(aging_group)
    return(list('scan2/tiny_objects/' + subset['sample'] + '.rda'))

config['aging_groups'] = dict((g, aging_group_to_scan2_objects(g)) for g in generic_groups)

# No MDA here. That requires signature B correction
config['aging_groups_to_model'] = {
    'pta': [ 'pta_neuron', 'pta_oligo' ],
    'all': [ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap' ],
    'batch1_vs_batch2': [ 'pta_oligo_batch1', 'pta_oligo_batch2' ],
    'pta_oligo_batch1': [ 'pta_neuron', 'pta_oligo_batch1' ],
    'pta_oligo_batch2': [ 'pta_neuron', 'pta_oligo_batch2' ]
}

config['mutsig_groups_for_de_novo'] = {
    'all': config['all_single_cells'],
    'pta': list(meta[meta["amp"] == "PTA"]['sample']),
    'mda': list(meta[meta["amp"] == "MDA"]['sample'])
}

config['mutsig_groups_for_signature_inclusion'] = [ 'pta_neuron', 'pta_oligo' ]

config['cosmic_vs_age_group'] = config['aging_groups_to_model']



snv_qualtypes = [ 'A', 'AB' ]
indel_qualtypes = [ 'indel_A', 'indel_AB' ]
all_qualtypes = snv_qualtypes + indel_qualtypes

# Allow script to run (and presumably create this file) by specifying
# --config make_pcawg_metadata=1 --until metadata/pcawg_metadata.csv
#
# This has to be a conditional statement because this same script generates
# this file. I think it may be possible to modify config[] globally from within
# a rule 
if 'make_pcawg_metadata' not in config.keys():
    # List of samples in ICGC/TCGA and associated tumor types
    pcawg_metadata = pd.read_csv('metadata/pcawg_metadata.csv')
    config['pcawg_metadata'] = pd.read_csv('metadata/pcawg_metadata.csv')
    config['pcawg_proj_map'] = dict(zip(list(pcawg_metadata['icgc_donor_id']), list(pcawg_metadata['project'])))
    config['pcawg_tumors'] = sorted(set(pcawg_metadata['tumor']))


# Constant config variables for the enrichment pipeline
binsizes = [ '1000' ]
qsizes = [ 3, 5, 10 ] #, 50 ]
qsizes_to_compute = [ 10 ] #, 50 ]


# Enrichment analyses are keyed by {group_name}___{qualtype}, i.e., pta_neuron___indel_A.
# These keys need to be mapped to mutation tables (i.e., actual SCAN2 calls), permutation
# objects containing mutation tables shuffled across the genome and (for analysis of
# signature enrichment) the COSMIC signatures determined to be active.
mutclass_to_mutfile = {}
mutclass_to_permfile = {}
mutclass_to_cosmic = {}
for group_name in generic_groups + synthetic_groups:
    for qualtype in all_qualtypes:
        analysis_key = group_name + "___" + qualtype

        # The active COSMIC signature set is determined from VAF-based (quality type A or indel_A)
        # SCAN2 calls, not signature-rescued calls that can have biased mutation signatures.
        cosmic_qualtype = qualtype
        if qualtype == 'AB':
            cosmic_qualtype = "A"
        if qualtype == 'indel_AB':
            cosmic_qualtype = "indel_A"
        muttype = "indel" if qualtype.startswith("indel") else "snv"
        calltype = "rescue" if qualtype.endswith("AB") else "pass"
        mutclass_to_mutfile[analysis_key] = "tables/" + group_name + "___FILTERED_mut___" + qualtype + ".csv"
        mutclass_to_permfile[analysis_key] = "scan2/permtool/" + group_name + "/perms_" + muttype + "_" + calltype + ".rda"
        if analysis_key not in mutclass_to_cosmic.keys():
            mutclass_to_cosmic[analysis_key] = {}
        mutclass_to_cosmic[analysis_key]['ad_hoc_signature_selection'] = "mutsigs/ad_hoc_signature_selection/cosmic_reduced___" + cosmic_qualtype + ".csv"
        mutclass_to_cosmic[analysis_key]['sigprofilerextractor'] = "mutsigs/sigprofilerextractor/cosmic_reduced___" + cosmic_qualtype + ".csv"



# The output directory and signal files are the only parameters that should
# change between analyses.
#
# Enrichment will be computed on all genome tile sets (corresponding to bin
# sizes) and qsizes specified here, so only list what needs to be computed.
# Other genome tile sets (like the 1MB tiles used for cancer) should not be
# listed here.
#
# If a different tile set is needed for a specific module (e.g., for cancer
# SNV density), make a different dictionary.  This is the default setup.
config['enrichment_config'] = {
    'qbed_from_bigwig_script': 'snakemake/scripts/make_qbed_from_bigwig.sh',
    'quantiles': qsizes,
    # must match binsizes.
    'tiles': {
        '1000':    'alignability/genome_tiles/genome_tiles_1000binsize.bed'
    },
    'masks': {
        '1000':    'alignability/genome_tiles/genome_mask_1000binsize.bed'
    },
    'mutclass_to_mutfile': mutclass_to_mutfile,
    'mutclass_to_permfile': mutclass_to_permfile,
    'mutclass_to_cosmic': mutclass_to_cosmic
}

# For any scenario where we want to correlate to cancer SNV density
# we need a much larger binsize to see a correlation.
# Here the binsize of primary utility is 1MB (which were used in, e.g.,
# the cell of origin papers).
# 1kb bins are kept around for academic purposes (and since all covariates
# are analyzed at this binsize by default, we get the results for relatively
# little work).
config['cancer_enrichment_config'] = {
    'qbed_from_bigwig_script': 'snakemake/scripts/make_qbed_from_bigwig.sh',
    'quantiles': [ '3', '10' ], #, '50' ],
    # must match binsizes.
    'tiles': {
        '1000':    'alignability/genome_tiles/genome_tiles_1000binsize.bed',
        '1000000':    'alignability/genome_tiles/genome_tiles_1000000binsize.bed'
    },
    'masks': {
        '1000':    'alignability/genome_tiles/genome_mask_1000binsize.bed',
        '1000000':    'alignability/genome_tiles/genome_mask_1000000binsize.bed'
    },
    'mutclass_to_mutfile': mutclass_to_mutfile,
    'mutclass_to_permfile': mutclass_to_permfile,
    'mutclass_to_cosmic': mutclass_to_cosmic
}


#################################################################################
# Data sources that provide genomic covariates for enrichment analyses.
#################################################################################

# Min coverage ("mc") values 02 = 20%, 08 = 80% mean that only bins
# covered >=20% or >=80% (these are separate analyses) by the relevant data
# sources are included when computing
# quantiles.  I.e., for gene expression from GTEx, genomic bins that are not
# transcribed at all are completely excluded before calculating quantiles of
# expression.  If these bins were included, the expression distribution would
# have a very large spike at expression=0.
# 
# Min coverage values: when using very small bins (like 1kb), the exact min
# coverage value has little effect (data not shown).  It's essentially binary
# for =0 or >0. The value matters more for large bins like the 1 MB bins used
# for cancer analysis. In that case, requiring 80% coverage excludes ~90% of
# the genome.
#
# IMPORTANT: the average bin value we compute accounts for coverage by assigning
# a value of 0 to any bases not covered. E.g., a bin with 450 bp covered by gene
# G and 550 bp not transcribed would be averaged such that
#    bin-wide average expression value = 0.45*(G's expression # level) + 0.55*0
#
# Sources no longer used:
#    'encode_replichip'
quantile_datasources = [ 'gtex_expression_mc' + x for x in [ '02', '08' ] ] + \
                [ 'scrnaseq_expression_mc' + x for x in [ '02', '08' ] ] + \
                [ 'nott', 'repliseq', 'conservation', 
                  'scatacseq', 'cancer_snvdens', 'roadmap_histone_signal_brain' ]

config['quantile_beds_for_sensitivity'] = []
with open('manifests/QBEDS_FOR_SENSITIVITY_ANALYSIS.MANIFEST', 'r') as f:
    for line in f:
        config['quantile_beds_for_sensitivity'].append(line.strip())
        

# Some other data sources no longer used:
#     'boca2', 'hic_tads'
bed_region_datasources = [ 'dna_repair_hotspots',
                            # 'gencode',   # can no longer allow this because it's a substring of gencode_simplified
                           # requires some hackery because the datasource internally recorded in BED
                           # files, enrichment objects, tables, etc. is "gencode", not "gencode_full".
                           # would need to rerun (with an updated GENCODE.MANIFEST) to fix this, but
                           # the time required to do that isn't worth the wait.
                           'gencode_full',
                           'gencode_simplified',
                           'gene_panels',
                           'gtex', 'gtex_genes', 'nott', 'roadmap_chromhmm_brain' ]

config['region_beds_for_sensitivity'] = []
with open('manifests/BEDS_FOR_SENSITIVITY_ANALYSIS.MANIFEST', 'r') as f:
    for line in f:
        config['region_beds_for_sensitivity'].append(line.strip())


wildcard_constraints:
    # snakemake seems not to match empty strings for a wildcard
    underscore='|_',           # allow either empty string or an underscore
    dot='|\.',                  # allow either empty string or a dot
    corrected='|corrected',
    datasource='|'.join(quantile_datasources + bed_region_datasources),
    sigtype='quantile|bed_regions',
    analysistype='bedenrich|qbedenrich|sigenrich_sigprofilerextractor|sigenrich_ad_hoc_signature_selection',
    ageclass='|'.join(ageclasses),
    mdatype='mda_gfap|mda_sox10',
    nmf_spectype='ID|SBS',
    sigprofiler_spectype='SBS96|SBS384|ID83',
    de_novo_group='|'.join(config['mutsig_groups_for_de_novo'].keys()),
    filter='FILTERED|UNFILTERED',
    generic_group='|'.join(generic_groups),
    rescue_group='|'.join(scan2_rescue_groups),
    synthetic_group='|'.join(synthetic_groups),
    # same as above, but allows for {synthetic_group1}_vs_{synthetic_group2} style outputs
    synthetic_group1='|'.join(synthetic_groups),  
    synthetic_group2='|'.join(synthetic_groups),
    any_group='|'.join(config['all_groups']),
    # same as above
    any_group1='|'.join(config['all_groups']),
    any_group2='|'.join(config['all_groups']),
    rescue_or_synthetic_group='|'.join(scan2_rescue_groups + synthetic_groups),
    mutsig_group='|'.join(generic_groups),
    cosmic_vs_age_group='|'.join(config['cosmic_vs_age_group'].keys()),
    binsize='|'.join([ '200', '1000', '1000000' ]),
    qualtype='|'.join(all_qualtypes),
    cosmic='cosmic_full|cosmic_reduced',
    cancer_project='tcga|icgc',
    mutsig_selection_method='ad_hoc_signature_selection|sigprofilerextractor',
    muttype='snv|indel',
    donor='|'.join(config['all_donors']),
    tumor='|'.join(config['pcawg_tumors'])  # Not necessary, but helps to catch errors
    #tumor='[^\.]+',  # No longer need this -[^\.]'   # Tumor codes are formatted XXXX-YYYY 
    #mutclass='|'.join(expand("{celltype}{sigclass}___{qualtype}",
        #celltype=celltypes, sigclass=[ '', '_sbs1', '_sbs16', '_sbs32' ], qualtype=qualtypes)),
    #chr='|'.join([ str(i) for i in range(1,23) ]),
    #panel_letter='a|b|c|d|e|f|g|h|i|j|k|l',
    #sig='sbs1|sbs16|sbs32',  # for "simplified" analysis of sbs1 and sbs16 enrichment using CG:C>T and ATN:T>C rather than signature fitting
    #half='|_half1|_half2',
    #umap='atac|rna',


rule scan2_panel_setup:
    input:
        "scan2/panel/makepanel/scan.yaml"

rule scan2_panel_run:
    input:
        "scan2/panel/makepanel/panel/panel.tab.gz",
        "scan2/panel/makepanel/makepanel_collected_benchmarks.txt"

rule scan2_setup:
    input:
        expand("scan2/{donor}/scan2/scan.yaml", donor=bams.keys())

def scan2_unpack_donors_and_samples(bams):
    ret = []
    for donor in bams.keys():
        ret = ret + expand("scan2/{donor}/scan2/sensitivity/{sample}/scan2_object.rda",
            donor=donor, sample=bams[donor]['single_cell'])
    return(ret)

rule scan2_call:
    input:
        scan2_unpack_donors_and_samples(bams)

rule scan2_rescue:
    input:
        expand('scan2/rescue_{rescue_group}/rescued_muts.txt',
            rescue_group=scan2_rescue_groups),
        expand('scan2/rescue_{rescue_group}/sig_homogeneity_tests.txt',
            rescue_group=scan2_rescue_groups)

rule scan2_digest:
    input:
        expand('scan2/{rescue_group}_mutations.{filter_status}.txt',
            rescue_group=scan2_rescue_groups,
            filter_status=[ 'FILTERED', 'UNFILTERED' ])

rule scan2_permtool:
    input:
        expand('scan2/permtool/{rescue_group}/perms_{muttype}_{passtype}.rda',
            rescue_group=scan2_rescue_groups,
            muttype=[ 'snv', 'indel' ],
            passtype=[ 'pass', 'rescue' ])

rule scan2_objects:
    input:
        expand('scan2/{size}_objects/{sample}.rda',
            size=[ 'full', 'tiny' ], sample=config['all_single_cells'])

rule chrx:
    input:
        expand("chrX/{donor}/mmq60.tab.{ext}",
            donor=bams.keys(), ext=[ 'gz', 'gz.tbi' ])

rule scan2_metrics:
    input:
        "suppfigX/all_panels.pdf",
        "suppfigX/metrics.csv",
        expand('metrics/{sample}.{filetype}.txt',
                sample=config['all_single_cells'],
                filetype=[ 'metrics', 'depth' ])

rule sigprofilerextractor:
    input:
        # de novo extracted signatures
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{spectype}/{spectype}/Suggested_Solution/{spectype}_De-Novo_Solution/Signatures/{spectype}_De-Novo_Signatures.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            spectype=[ 'SBS96', 'ID83' ]),
        # Assignment of COSMIC signatures to de novo extracted signatures
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{spectype}/{spectype}/Suggested_Solution/COSMIC_{spectype}_Decomposed_Solution/Activities/COSMIC_{spectype}_Activities.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            spectype=[ 'SBS96', 'ID83' ]),
            
rule mapd:
    input:
        expand("mapd/{sample}.mapd.txt", sample=config['all_samples'])


# Same as above for SCAN2 output
def ginkgo_unpack_donors_and_samples(bams):
    ret = []
    for donor in bams.keys():
        ret = ret + expand("ginkgo/{donor}/{sample}_{plottype}.jpeg",
                donor=donor,
                sample=list(bams[donor]['single_cell'].keys()) + list(bams[donor]['bulk'].keys()),
                plottype=[ 'CN', 'GC', 'SoS', 'counts', 'dist', 'hist', 'lorenz' ])
    return(ret)

rule ginkgo:
    input:
        # These are all plots
        ginkgo_unpack_donors_and_samples(bams),
        # These are the tables used to construct plots in case raw data is useful
        data=expand('ginkgo/{donor}/{table}',
            donor=bams.keys(),
            table=[ 'data', 'CNV1', 'CNV2', 'SegBreaks', 'SegCopy', 'SegFixed', 'SegNorm', 'SegStats'])


rule alignability:
    input:
        expand('alignability/genome_tiles/genome_mask_{binsize}binsize.bed',
            binsize=[ 200, 1000, 1000000 ])


rule aging_rates:
    input:
        expand('aging_rates/{age_group}___{analysis}___{qualtype}.csv',
            age_group=config['aging_groups_to_model'].keys(),
            analysis=[ 'mutburden_combined', 'mutburden_models' ],
            qualtype=[ 'A', 'indel_A' ]),  # only passA calls are used


# For now this is just signature fitting. In both projects so far,
# de novo analysis produced only one signature.
rule mutsigs:
    input:
        expand("mutsigs/raw_spectra/{group}___raw_spectrum___{qualtype}.{output}",
            group=generic_groups,
            qualtype=[ 'A', 'indel_A' ],
            output=[ 'pdf', 'svg', 'csv' ]),
        expand("mutsigs/ad_hoc_signature_selection/cosmic_signature_inclusion/all___signature_selection___{qualtype}.csv",
            qualtype=[ 'A', 'indel_A' ]),
        expand("mutsigs/ad_hoc_signature_selection/cosmic_aging/{group}___barplots___{qualtype}.{output}",
            group=generic_groups,
            qualtype=[ 'A', 'indel_A' ],
            output=[ 'pdf', 'svg' ]),
        expand("mutsigs/ad_hoc_signature_selection/cosmic_aging/{group}___cosmic_models_vs_age___{qualtype}.{output}",
            group=config['cosmic_vs_age_group'].keys(),
            qualtype=[ 'A', 'indel_A' ],
            output=[ 'pdf', 'svg', 'csv' ]),
        # SigProfilerExtractor output. Eventually either this or ad_hoc_signature_selection will be unnecessary.
        # Output for choosing the number of active signatures
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/{sigprofiler_spectype}_selection_plot.pdf',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ]),
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/All_solutions_stat.csv',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ]),
        # The spectra and per-cell exposures of the de novo extracted signatures
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/Suggested_Solution/{sigprofiler_spectype}_De-Novo_Solution/Activities/{sigprofiler_spectype}_De-Novo_Activities_refit.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ]),
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/Suggested_Solution/{sigprofiler_spectype}_De-Novo_Solution/Signatures/{sigprofiler_spectype}_De-Novo_Signatures.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ]),
        # The COSMIC signatures that presumably make up the de novo extracted signatures
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/Suggested_Solution/COSMIC_{sigprofiler_spectype}_Decomposed_Solution/Activities/COSMIC_{sigprofiler_spectype}_Activities.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ]),
        expand('mutsigs/sigprofilerextractor/{de_novo_group}/{sigprofiler_spectype}/{sigprofiler_spectype}/Suggested_Solution/COSMIC_{sigprofiler_spectype}_Decomposed_Solution/Signatures/COSMIC_{sigprofiler_spectype}_Signatures.txt',
            de_novo_group=config['mutsig_groups_for_de_novo'].keys(),
            sigprofiler_spectype=[ 'SBS96', 'ID83' ])


# For now, "shared" only means shared by exactly two cells in the same
# individual. Higher order
# sharing within an individual is not examined.  This is independent of
# the sharing filters applied prior to enrichment analysis that remove
# recurrent mutations across individuals (likely artifacts) and retain only
# 1 mutation if it recurs across cells in a single individual (likely lineage
# events that occurred only once, so should count only once for enrichment
# purposes).
#
# mutsig_selection_method: we also try to predict age and time to MRCA using
# SBS1 level, which has been shown to correlate with cell division rate.
# the mutsig selection method therefore influences how much SBS1 is estimated
# in the shared and private mutation sets.
rule shared_mutations:
    input:
        expand("shared_mutations/{mutsig_selection_method}/{sample_pair}___{filetype}.csv",
            mutsig_selection_method=[ 'sigprofilerextractor' ],
            sample_pair=[ tup[0] + "___vs___" + tup[1] for donor in bams.keys() \
                for tup in itertools.combinations(bams[donor]['single_cell'].keys(), r=2) ],
            filetype=[ 'mutations', 'mrca' ])



print("REMINDER: should only use passA mutations for MDA as well because signature rescue is not designed for MDA (reminder only; this is how the pipeline currently works).")
# Enrichment analysis of total mutation burden
rule enrichment:
    input:
        # All quantile-based regions
        expand('enrichment/{datasource}/quantile/{group}___{qualtype}.{nquantiles}quantiles.{output}',
            group=generic_groups + synthetic_groups,
            qualtype=all_qualtypes,
            nquantiles=qsizes_to_compute,
            datasource=quantile_datasources,
            output=[ 'svg', 'pdf', 'csv' ]),
        # All regions directly specified by BED files
        expand('enrichment/{datasource}/bed_regions/{group}___{qualtype}.{output}',
            group=generic_groups + synthetic_groups,
            qualtype=all_qualtypes,
            datasource=bed_region_datasources,
            output=[ 'svg', 'pdf', 'csv' ])

# Region-specific sensitivity estimates
rule quantile_enrichment_sensitivity:
    input:
        expand('enrichment/sensitivity/quantile/{sample}_sensitivity.txt',
            #sample=config['all_pta_cells'])
            sample=config['all_single_cells'])   # try adding MDA as well

rule bed_enrichment_sensitivity:
    input:
        expand('enrichment/sensitivity/bed_regions/{sample}_sensitivity.{file}.txt',
            #sample=config['all_pta_cells'],
            sample=config['all_single_cells'],   # try adding MDA as well
            file=[ 'full', 'summary' ]),
        expand('enrichment/sensitivity/bed_regions/{sample}_depth.{file}.txt',
            #sample=config['all_pta_cells'],
            sample=config['all_single_cells'],   # try adding MDA as well
            file=[ 'full', 'summary' ])

rule mb_tile_sensitivity:
    input:
        expand('enrichment/sensitivity/tiles_1000000binsize/{sample}.csv',
            sample=config['all_single_cells']),
        expand('enrichment/sensitivity/tiles_1000000binsize/{group}.summary.txt',
            group=[ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap' ])


rule summarized_sensitivity:
    input:
        expand('enrichment/sensitivity/{group}.summary.txt',
            group=[ 'pta_neuron', 'pta_oligo',
                    'mda_sox10', 'mda_gfap']),
                    #'mda_sox10_elderly', 'mda_gfap_elderly' ])  # XXX: enable later
        "suppfig3_corrected/quantile_sensitivity_panels.pdf"
        

# TEMPORARY: manually specify the subset of signals with sensitivity corrections
# These tables feed into fig4 and suppfig3 rules to produce plots.
rule correct_enrichment_analyses:
    input:
        expand('enrichment/{datasource}/quantile/{group}___{qualtype}.10quantiles.corrected.csv',
                group=[ 'pta_neuron', 'pta_oligo' ],
                datasource=[ 'gtex_expression_mc02', 'scrnaseq_expression_mc02', 'scatacseq', 'repliseq', 'roadmap_histone_signal_brain' ],
                qualtype=[ 'A', 'indel_A', 'AB', 'indel_AB' ]),
        expand('enrichment/{datasource}/bed_regions/{group}___{qualtype}.corrected.csv',
                group=[ 'pta_neuron', 'pta_oligo' ],
                datasource=[ 'roadmap_chromhmm_brain', 'nott' ],
                qualtype=[ 'A', 'indel_A', 'AB', 'indel_AB' ]),
        expand('enrichment/{datasource}/quantile/{group}___{qualtype}.{nquantiles}quantiles_sigenrich_{mutsig_selection_method}.corrected.{output}',
            datasource=quantile_datasources,
            group=generic_groups + synthetic_groups,
            qualtype=[ 'A', 'indel_A' ],
            nquantiles=[ 3 ],
            mutsig_selection_method=[ 'ad_hoc_signature_selection', 'sigprofilerextractor' ],
            output=[ 'svg', 'pdf', 'csv' ])

rule enrichment_sensitivity:
    input:
        rules.quantile_enrichment_sensitivity.input,
        rules.bed_enrichment_sensitivity.input,
        rules.correct_enrichment_analyses.input


# Enrichment analysis of signature-specific mutation burden
# In theory would be done to all regions tested for total burden enrichment,
# but because of signature fitting inaccuracy, regions must be large.
rule signature_enrichment:
    input:
        expand('enrichment/{datasource}/quantile/{group}___{qualtype}.{nquantiles}quantiles_sigenrich_{mutsig_selection_method}.{output}',
            datasource=quantile_datasources,
            group=generic_groups + synthetic_groups,
            qualtype=[ 'A', 'indel_A' ],
            nquantiles=[ 3 ],
            mutsig_selection_method=[ 'ad_hoc_signature_selection', 'sigprofilerextractor' ],
            output=[ 'svg', 'pdf', 'csv' ]),


'''
rule spatial_enrichment:
    input:
        expand('enrichment/spatial_burden/{celltype}___{qualtype}___{binsize}binsize___{rolling}rolling.profile.csv',
            celltype=[ 'oligo', 'neuron', 'oligo_mdapta', 'oligo_mda_2infants', 'oligo_mda_2elderly' ],
            qualtype=[ 'A', 'AB' ],
            binsize=[ '100000', '1000000' ],
            rolling=[ '1', '10' ])
'''


rule cancer:
    input:
        expand("cancer_genes/odds_ratios/{group1_vs_group2}.csv",
            group1_vs_group2=[ tup[0] + "___vs___" + tup[1] 
                for tup in itertools.combinations(generic_groups + synthetic_groups, r=2) ])


rule response:
    input:
        expand("respfig1/{group}_genes{inset}.pdf",
            # MDA gene enrichments
            group=[ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap', 'mda_sox10_elderly', 'mda_gfap_elderly' ],
            inset=[ '', '_inset' ]),
        "respfig2/pta_neuron_half1_vs_pta_oligo_half1.corrected.pdf",
        #"respfig2/pta_neuron_half2_vs_pta_neuron_half2.corrected.csv",
        "respfig2/pta_neuron_half2_vs_pta_oligo_half2.corrected.pdf",
        #"respfig2/pta_oligo_half2_vs_pta_oligo_half2.corrected.csv",
        "respfig2/pta_neuron_vs_pta_oligo_batch1.corrected.pdf",
        "respfig2/pta_neuron_vs_mda_sox10_elderly.corrected.pdf",
        "respfig2/pta_neuron_vs_mda_gfap_elderly.corrected.pdf",
        "respfig2/pta_neuron_vs_pta_oligo.corrected.pdf",
        "respfig2/panel_h_chromhmm___snv.corrected.pdf",
        "respfig2/panel_i_nott_enhprom___snv.corrected.pdf",
        expand("respfig3/{donor}.pdf",
            donor=config['all_donors']), #[ '5559', '5657' ]),
        "respfig4/all_panels.pdf",
        "respfig6/panels_cdefg_enrichment_analyses_pta_neuron_vs_pta_oligo.corrected.pdf",
        "respfig6/quantile_scatter_plots.pdf",
        "respfig6/panel_h_chromhmm___snv.corrected.pdf",
        "respfig6/panel_i_nott_enhprom___snv.corrected.pdf"



include: "snakefile.data"
include: "snakefile.scan2"
include: "snakefile.scan2_per_donor"
include: "snakefile.sentieon_for_chrX"
include: "snakefile.mapd"
include: "snakefile.suppfig_qual"
include: "snakefile.ginkgo"
include: "snakefile.ginkgo_per_donor"
include: "snakefile.aging_rates"
include: "snakefile.mutsigs"
include: "snakefile.shared_mutations"
include: "snakefile.alignability"
include: "snakefile.scatacseq"
include: "snakefile.gtex_enrichment"
include: "snakefile.scrnaseq_enrichment"
include: "snakefile.nott_enrichment"
include: "snakefile.boca_enrichment"
include: "snakefile.dnarepair_enrichment"
include: "snakefile.gene_region_enrichment"
include: "snakefile.spatial_enrichment"
include: "snakefile.other_enrichment"
include: "snakefile.snpeff_dndscv_cancer"
include: "snakefile.enrichment_sensitivity"
include: "snakefile.fig1"
include: "snakefile.fig2"
include: "snakefile.fig3"
include: "snakefile.fig4"
include: "snakefile.fig5"
include: "snakefile.fig6"
include: "snakefile.figX"
include: "snakefile.suppfig2"
include: "snakefile.suppfig3"
include: "snakefile.suppfig4"
include: "snakefile.response"
include: "snakefile.table1"
include: "snakefile.supptables"

# Shortcuts to rebuild a single figure/table at a time

# These two CSVs need to be joined by hand
rule table1:
    input:
        expand("table1/{amptype}_{file}.csv",
            amptype=[ 'pta' ], #, 'mda' ],   # mda doesn't work because it implies mda_neurons exists
            file=[ 'cells', 'muts' ])


rule fig1:
    input:
        expand("fig1/panel_b_aging_rates_{comparison}{qualtype}{file}",
            file=[ ".pdf", "_burdens.csv", "_model.csv" ],
            qualtype=[ 'A', 'indel_A' ],
            comparison=[ '', 'all_comparisons_', 'batch1_vs_batch2_' ]),
        expand("fig1/panel_c_{datasource}{comparison}___{muttype}.{ext}",
            datasource=[ 'gtex', 'gencode_simplified', 'gencode_full' ],
            comparison=[ '', '_all_comparisons' ],
            muttype=[ 'snv', 'indel' ],
            ext=[ 'svg', 'pdf' ]),
        expand("fig1_corrected/panel_c_{datasource}{comparison}___{muttype}.corrected.{ext}",
            datasource=[ 'gtex', 'gencode_simplified', 'gencode_full' ],
            comparison=[ '', '_all_comparisons' ],
            muttype=[ 'snv', 'indel' ],
            ext=[ 'svg', 'pdf' ]),
        expand("fig1/panel_d_snpeff{comparison}___{muttype}.{ext}",
            comparison=[ '', '_all_comparisons' ],
            muttype=[ 'snv', 'indel' ],
            ext=[ 'svg', 'pdf' ])


rule suppfig2:
    input:
        "suppfig2/orthogonal_tech_comparison.pdf",
        expand("suppfig2/panel_a_{group}_ins_del_aging_rates.pdf",
                group=[ 'pta_neuron', 'pta_oligo' ]),
        "suppfig2/panel_b_indelsize.pdf",
        "suppfig2/panel_b_indelsize.csv",
        expand('suppfig2/panel_c_{group}.{ext}',
            group=[ 'mda_gfap', 'mda_sox10', 'mda_gfap_elderly', 'mda_gfap_infant', 'mda_sox10_elderly', 'mda_sox10_infant' ],
            ext=[ 'pdf', 'csv' ]),
        expand('suppfig2_corrected/panel_c_{group}.{ext}',
            group=[ 'mda_gfap', 'mda_sox10', 'mda_gfap_elderly', 'mda_gfap_infant', 'mda_sox10_elderly', 'mda_sox10_infant' ],
            ext=[ 'corrected.pdf', 'corrected.csv' ]),
        # Above plots are individual groups, this plots PTA OL vs. MDA OL vs. MDA GFAP
        expand('suppfig2_corrected/panel_c_gtex_pta_vs_mda___snv.{ext}',
            ext=[ 'corrected.pdf', 'corrected.svg' ]),
        "suppfig2/panel_d_genes.pdf",
        "suppfig2/panel_d_genes.jpeg",
        "suppfig2/panel_d_genes.csv"


rule suppfig3:
    input:
        expand('suppfig3/panel_a_gtex_expression_{group}___{muttype}.{ext}',
            group=[ 'pta_neuron', 'pta_oligo' ],
            muttype=[ 'AB', 'indel_AB' ],
            ext=[ 'pdf', 'csv' ]),
        expand('suppfig3_corrected/panel_a_gtex_expression_{group}___{muttype}.corrected.{ext}',
            group=[ 'pta_neuron', 'pta_oligo' ],
            muttype=[ 'AB', 'indel_AB' ],
            ext=[ 'pdf', 'csv' ]),
        expand("suppfig3/panel_b_repliseq___{muttype}.{ext}",
            muttype=[ 'AB', 'indel_AB' ],
            ext=[ 'pdf', 'csv' ]),
        expand("suppfig3_corrected/panel_b_repliseq___{muttype}.corrected.{ext}",
            muttype=[ 'AB', 'indel_AB' ],
            ext=[ 'pdf', 'csv' ]),
        "suppfig3_corrected/quantile_sensitivity_panels.pdf"
        # Removed for space reasons
        #"suppfig3/panel_c_chromhmm_tss.pdf",
        #"suppfig3/panel_c_chromhmm_tss.csv"


rule suppfig4:
    input:
        "suppfig4/panel_a.pdf",
        "suppfig4/panel_a.csv",
        "suppfig4/panel_b.pdf",
        "suppfig4/panel_b.csv"


rule fig2:
    input:
        "fig2/panel_a.pdf",
        "fig2/panel_a.csv",
        expand("fig2/panel_a_raw_spectrum_{group}_A.{ext}",
            group=config['comparison_groups'],
            ext=[ 'pdf', 'csv' ]),
        expand("fig2{method}/panel_b___{group}___A.{ext}",
            #method=[ '', '_sigprofilerextractor' ],   # No longer necessary to do the old ad-hoc method
            method=[ '_sigprofilerextractor' ],
            group=[ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap' ],
            ext=[ 'pdf', 'csv' ]),
        expand("fig2{method}/panel_c_{comparison}_A.{ext}",
            #method=[ '', '_sigprofilerextractor' ],   # No longer necessary to do the old ad-hoc method
            method=[ '_sigprofilerextractor' ],
            ext=[ 'pdf', 'csv' ],
            comparison=[ 'pta', 'all', 'batch1_vs_batch2' ])


# This should really be numbered fig3. Let's wait to make sure
# there are no other renumberings.
rule figX:
    input:
        rules.shared_mutations.input,   # require all pairs to be run even though only 3 are used
        "figX/maybe_number_shared_snvs_panel.pdf",
        "figX/panel_a.pdf",
        "figX/panel_a_mrca_timings.csv",
        "figX/panel_b.pdf",
        "figX/panel_b_supplement.pdf",
        "figX/panel_b_spectra.csv",
        "figX/panel_b_exposures_barplot.csv",
        "figX/panel_b_exposures_barplot.pdf",
        "figX/panel_c_early_vs_late_spectrum.pdf",
        "figX/panel_d_infant.pdf",
        "figX/panel_d_spectra_infant.csv",
        "figX/panel_d_exposures_infant.csv"


rule fig3:
    input:
        "fig3/panel_a.pdf",
        "fig3/panel_a.csv",
        expand("fig3/panel_a_raw_spectrum_{group}_indel_A.{ext}",
            group=config['comparison_groups'],
            ext=[ 'pdf', 'csv' ]),
        expand("fig3{method}/panel_b___{group}___indel_A.{ext}",
            #method=[ '', '_sigprofilerextractor' ],   # No longer necessary to do the old ad-hoc method
            method=[ '_sigprofilerextractor' ],
            group=[ 'pta_neuron', 'pta_oligo', 'mda_sox10', 'mda_gfap' ],
            ext=[ 'pdf', 'csv' ]),
        expand("fig3{method}/panel_c_{comparison}_indel_A.{ext}",
            #method=[ '', '_sigprofilerextractor' ],   # No longer necessary to do the old ad-hoc method
            method=[ '_sigprofilerextractor' ],
            ext=[ 'pdf', 'csv' ],
            comparison=[ 'pta', 'all', 'batch1_vs_batch2' ])


rule fig4:
    input:
        "fig4/panel_a_umap_plot.pdf",
        "fig4/panel_c_umap_plot.pdf",
        expand("fig4/panels_cdefg_enrichment_analyses_{comparison}.pdf",
            comparison=config['all_comparisons']),
        # Barplots are different from the quantile plots above: all of the
        # comparisons can be shown in one barplot without it being too many
        # lines to read.
        # N.B. we don't do indel analysis on these regions because they can be
        # much smaller than the quantile-based regions and indels are much
        # sparser than sSNVs.
        expand("fig4/panel_h_chromhmm{comparison}___{muttype}.pdf",
            comparison=[ '', '_all_comparisons' ],  # '' = pta_neuron vs pta_oligo
            muttype=[ 'snv' ]), #, 'indel' ]),
        expand("fig4/panel_i_nott_enhprom{comparison}___{muttype}.pdf",
            comparison=[ '', '_all_comparisons' ],  # '' = pta_neuron vs pta_oligo
            muttype=[ 'snv' ]), #, 'indel' ]),
        expand("fig4_corrected/panels_cdefg_enrichment_analyses_{comparison}.corrected.pdf",
            comparison=config['all_comparisons']),
        expand("fig4_corrected/panel_h_chromhmm{comparison}___{muttype}.corrected.pdf",
            comparison=[ '', '_all_comparisons' ],  # '' = pta_neuron vs pta_oligo
            muttype=[ 'snv' ]), #, 'indel' ]),
        expand("fig4_corrected/panel_i_nott_enhprom{comparison}___{muttype}.corrected.pdf",
            comparison=[ '', '_all_comparisons' ],  # '' = pta_neuron vs pta_oligo
            muttype=[ 'snv' ]), #, 'indel' ])


rule fig5:
    input:
        "fig5/all_panels_enrichment_analyses.pdf",
        "fig5_sigprofilerextractor/all_panels_enrichment_analyses.pdf"


rule fig6:
    input:
        expand("fig6/panel_a_{comparison}.{ext}",
            comparison=config['all_comparisons'],
            ext=[ 'pdf', 'csv' ]),
        expand("fig6_corrected/panel_a_{comparison}.corrected.{ext}",
            comparison=config['all_comparisons'],
            ext=[ 'pdf', 'csv' ]),
        expand("fig6/panel_a_{group}.{ext}",
            group=config['comparison_groups'],
            ext=[ 'pdf', 'csv' ]),
        expand("fig6_corrected/panel_a_{group}.corrected.{ext}",
            group=config['comparison_groups'],
            ext=[ 'pdf', 'csv' ]),
        # Correction does not apply to any of the following analyses. See comments.
        # Panel b compares cancer mutations, NOT SCAN2 mutations, to scATACseq density.
        # Nothing to correct.
        "fig6/panel_b_barplot.pdf",
        "fig6/panel_b_heatmap.pdf",
        "fig6/panel_b.csv",
        # Panel c compares cancer mutations, NOT SCAN2 mutations, to scRNAseq density.
        # Nothing to correct.
        "fig6/panel_c_barplot.pdf",
        "fig6/panel_c_heatmap.pdf",
        "fig6/panel_c.csv",
        # Panel d does analyze SCAN2 mutations, so one might expect sensitivity correction.
        # However, the statistic reported is an odds ratio between neuron and oligo mutations
        # in the same region. Sensitivity does not change meaningfully between OLs and
        # neurons in the same region, so there is no need for correction.
        expand("fig6/panel_d_{comparison}.{ext}",
            # additions: normally we don't compare neurons to MDA glia
            comparison=config['all_comparisons'] + [ 'pta_neuron_vs_mda_sox10_elderly', 'pta_neuron_vs_mda_gfap_elderly' ],
            ext=[ 'pdf', 'csv' ])


rule suppfig5:
    input:
        # Same as panel 6d: odds ratios make sensitivity correction unnecessary.
        expand("suppfig5/cancer_gene_ors{full}_{comparison}.{ext}",
            comparison=config['all_comparisons'],
            full=[ '', '_full' ],
            ext=[ 'pdf' ])


# Catchall
rule misc:
    input:
        "scrnaseq/snRNA_1465a_table.csv",

# This must be defined below all other rules to use the rules.XXX.output directive.
rule all:
    input:
        rules.misc.input,
        rules.ginkgo.input,
        rules.mapd.input,
        rules.scan2_metrics.input,
        rules.response.input,
        rules.table1.input,
        "supptables/SuppTable1.csv",
        "supptables/SuppTable2.csv",
        rules.fig1.input,
        rules.fig2.input,
        rules.figX.input,
        rules.fig3.input,
        rules.fig4.input,
        rules.fig5.input,
        rules.fig6.input,
        rules.suppfig2.input,
        rules.suppfig3.input,
        rules.suppfig5.input,
    default_target: True
