# vim: syntax=python
#
#
# Inputs:
#    Pandas table file
#    -----------------
#    Pandas table files must be formatted as CSVs with
#    1 comma separated header line naming each metadata column.
#       - one column MUST be named "file" and contain the full path to
#         the file
#       - metadata columns in output tables will retain order from
#         the input tables.
#
#    - (mutation, permutation) sets
#       * metadata (k-tuple per set)
#
#    - bigwig signal files
#       * metadata (n-tuple per file)
#
#    Config dict
#    -----------
#    - [list] numbers of bins to split signal into
#    - [dict] BEDs tiling the genome into windows, used to average
#             bigwig signals. (binsize, filepath) dict
#    - output directory
# Outputs:
#    - [list] qbeds with both quantile determinations and raw signal
#    - [list] FULL and SUMMARY mutenrich outputs
#    - [list] integrated table over all combinations of (mut sets, qbeds)

import pandas as pd

def read_manifest(filename):
    manifest = pd.read_csv(filename)
    files = list(manifest['file'])
    m_nofiles = manifest.loc[:, manifest.columns != 'file'].astype(str)
    metadata = list(m_nofiles.columns)
    classes = m_nofiles.agg('___'.join, axis=1)
    manifest['__class__'] = classes
    #tmp = pd.concat([ "'" + m_nofiles.columns[i] + '=' + m_nofiles.iloc[:, i] + "'" \
    tmp = pd.concat([ m_nofiles.columns[i] + '=' + m_nofiles.iloc[:, i] \
        for i in range(0, m_nofiles.shape[1]) ], axis=1)
    metatags = list(tmp.agg(' '.join, axis=1))
    manifest['__metatags__'] = metatags
    #print(manifest)
    return(manifest, files, metadata, list(classes), metatags)


mut_manifest, mut_files, mut_metadata, mut_classes, mut_metatags = \
    read_manifest(config['MUT_MANIFEST'])

signal_manifest, signal_files, signal_metadata, signal_classes, signal_metatags = \
    read_manifest(config['SIGNAL_MANIFEST'])


outroot = config['output_dir'] + "/quantile"


rule enrichment_plot:
    input:
        outroot + '/{mutclass}/{nquantiles}quantiles.csv'
    output:
        expand(outroot + '/{{mutclass}}/{{nquantiles}}quantiles.{ext}',
            ext=[ 'svg', 'pdf', 'csv2' ])
    log:
        outroot + '/{mutclass}/{nquantiles}quantiles.log'
    params:
        ignore='enrichment_grid_R_ignore_none',
        # specify group=comma separated list of metadata names to group traces
        # by unique metadata combinations. Default 'datasource' just causes a
        # title to be printed. Won't work in workflows that don't have a datasource
        # metadata column.
        group='datasource',
        #highlight=''  # can use e.g., group=Brain to select lines to highlight
    resources:
        mem=4000
    script:
        "scripts/plot_enrichment_grid.R"


rule sigenrichment_plot:
    input:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich_adapted.csv'
    output:
        expand(outroot + '/{{mutclass}}/{{nquantiles}}quantiles_sigenrich.{ext}',
            ext=[ 'svg', 'pdf', 'csv2' ])
    log:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich.log'
    params:
        # neurons don't have SBS32, so the estimates have extremely high
        # variance. this leads to y-axes that are so big the other signatures
        # can't be seen.
        ignore=lambda wildcards: "sigclass=SBS32" if wildcards.mutclass.startswith('neuron') else 'enrichment_grid_R_ignore_none',
        group='datasource,sigclass',
        #highlight=''  # can use e.g., group=Brain to select lines to highlight
    resources:
        mem=4000
    script:
        "scripts/plot_enrichment_grid.R"


# All this does is break apart the "quantile" column which has
# the format quantile|||signature class.
rule adapt_sigenrichment_table:
    input:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich.csv'
    output:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich_adapted.csv'
    log:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich_adapted.log'
    resources:
        mem=1000
    script:
        "scripts/adapt_sigenrich_table.R"
    

rule sigenrichment_table:
    input:
        expand(outroot + "/{{mutclass}}/sigenrich/tiled_{binsize}binsize_{{nquantiles}}quantiles.SUMMARY.rda",
            binsize=config['tiles'].keys())
    output:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich.csv'
    log:
        outroot + '/{mutclass}/{nquantiles}quantiles_sigenrich.log'
    resources:
        mem=4000
    script:
        "scripts/make_enrichment_table.R"


# Final output rule
rule enrichment_table:
    input:
        expand(outroot + "/{{mutclass}}/qbedenrich/tiled_{binsize}binsize_{{nquantiles}}quantiles.SUMMARY.rda",
            binsize=config['tiles'].keys())
    output:
        outroot + '/{mutclass}/{nquantiles}quantiles.csv'
    log:
        outroot + '/{mutclass}/{nquantiles}quantiles.log'
    resources:
        mem=4000
    script:
        "scripts/make_enrichment_table.R"


rule sigenrichment_qbed_analysis:
    input:
        #cosmic='analysis/tables/cosmic_reduced___A.csv',
        # enable indel sigenrich for Nat. 2022 paper on ID4
        # COSMIC reduction is always performed on the non-rescue calls (="A" or "indel_A"),
        # because rescue can introduce signature biases.
        cosmic=lambda wildcards: 'analysis/tables/cosmic_reduced___' + ('indel_A' if wildcards.mutclass.split('___')[1].split('_')[0] == 'indel' else 'A') + '.csv',
        mut=lambda wildcards: mut_manifest.loc[mut_manifest['__class__'] == wildcards.mutclass, 'file'],
        perm=lambda wildcards: config['mut_to_perm'][wildcards.mutclass],
        qbeds=expand(outroot + "/qbed/{signalclass}.{{binsize}}binsize_{{nquantiles}}quantiles.qbed",
            signalclass=signal_classes)
    output:
        full=outroot + "/{mutclass}/sigenrich/tiled_{binsize}binsize_{nquantiles}quantiles.FULL.rda",
        summary=outroot + "/{mutclass}/sigenrich/tiled_{binsize}binsize_{nquantiles}quantiles.SUMMARY.rda",
    params:
        # bootstraps on sigenrich is not yet supported
        nbootstraps=0,
        # unfortunately i haven't standardized the column name for mutation signatures
        # this relies on mutation classes being called "A", "AB", etc. for SNVs and
        # "indel_A", "indel_AB", etc. for indels.
        colname_for_sig=lambda wildcards: 'muttype' if wildcards.mutclass.split('___')[1].split('_')[0]=='indel' else 'mutclass'
    resources:
        # XXX: update me: so far, these RAM values work with my data.
        mem=lambda wildcards: 40000 if wildcards.binsize == '1000' or wildcards.nquantiles == '50' else 20000
    log:
        summary=outroot + "/{mutclass}/sigenrich/tiled_{binsize}binsize_{nquantiles}quantiles.log"
    benchmark:
        outroot + "/{mutclass}/sigenrich/tiled_{binsize}binsize_{nquantiles}quantiles.benchmark.txt"
    script:
        "scripts/sigenrich.R"


rule enrichment_qbed_analysis:
    input:
        mut=lambda wildcards: mut_manifest.loc[mut_manifest['__class__'] == wildcards.mutclass, 'file'],
        perm=lambda wildcards: config['mut_to_perm'][wildcards.mutclass],
        qbeds=expand(outroot + "/qbed/{signalclass}.{{binsize}}binsize_{{nquantiles}}quantiles.qbed",
            signalclass=signal_classes)
    output:
        full=outroot + "/{mutclass}/qbedenrich/tiled_{binsize}binsize_{nquantiles}quantiles.FULL.rda",
        summary=outroot + "/{mutclass}/qbedenrich/tiled_{binsize}binsize_{nquantiles}quantiles.SUMMARY.rda",
    params:
        nbootstraps=10000
    resources:
        # XXX: update me: so far, these RAM values work with my data.
        mem=lambda wildcards: 32000 if wildcards.binsize == '1000' else 10000
    log:
        summary=outroot + "/{mutclass}/qbedenrich/tiled_{binsize}binsize_{nquantiles}quantiles.log"
    benchmark:
        outroot + "/{mutclass}/qbedenrich/tiled_{binsize}binsize_{nquantiles}quantiles.benchmark.txt"
    script:
        "scripts/qbedenrich.R"


# extratags must be a list of strings formatted as STRING=STRING
def make_qbed_from_bigwig_params(min_coverage, extratags=[]):
    return dict({
        # can't figure out why this won't work in the shell command
        #script=workflow.source_path('scripts/make_qbed_from_bigwig.sh'),
        # We manually roll up (quantile, binsize) pairs into a single rule
        # because multiplying the number of input files by 16 (in this
        # project) makes snakemake very slow.
        'script' : config['qbed_from_bigwig_script'],
        # New option that allows tiles to be excluded based on the fraction
        # of the tile covered by the bigwig signal. 0 means no tiles are
        # excluded. In qbedenrich (the enrichment analysis), exclusion by
        # this method is indistinguishable to exclusion by alignability.
        'min_coverage' : min_coverage,
        'output_pre' : outroot + "/qbed/{signalclass}",
        'quantile_array' : " ".join([ str(x) for x in config['quantiles'] ]),
        # tiles, binsizes and metatags must all be the same length
        'tile_array' : " ".join([ "'" + f + "'" for f in config['tiles'].values() ]),
        'binsize_array' : " ".join([ "'" + bs + "'" for bs in config['tiles'].keys() ]),
        'metatag_array' : lambda wildcards: " ".join([ "'" + mt + "'"
            for mt in [ "BINSIZE=" + binsize + " " + list(signal_manifest.loc[signal_manifest['__class__'] == wildcards.signalclass, '__metatags__'])[0] \
                    for binsize in config['tiles'].keys() ] ]) + \
            " ".join(extratags)
    })


# dummy1 and dummy2 are not used, they're only here to require that they
# be created before running this workflow.
# XXX: actually, I don't think this is necessary anymore
rule make_qbed_from_bigwig:
    input:
        #dummy1=config['MUT_MANIFEST'],
        #dummy2=config['SIGNAL_MANIFEST'],
        tiles=lambda wildcards: config['tiles'].values(),
        bigwig=lambda wildcards: list(signal_manifest.loc[signal_manifest['__class__'] == wildcards.signalclass, 'file'])[0]
    output:
        qbed=expand(outroot + "/qbed/{{signalclass}}.{binsize}binsize_{nquantiles}quantiles.qbed",
            binsize=config['tiles'].keys(),
            nquantiles=config['quantiles']),
        tmp1=temp(outroot + "/qbed/{signalclass}.tmp1"),
        tmp2=temp(outroot + "/qbed/{signalclass}.tmp2.sig") # must end in .sig
    params:
        **make_qbed_from_bigwig_params(0)
    log:
        outroot + "/qbed/{signalclass}.log"
    benchmark:
        outroot + "/qbed/{signalclass}.benchmark.txt"
    resources:
        mem=7000
    shell:
        """
        set -euo pipefail
        quantiles=({params[quantile_array]})
        binsizes=({params[binsize_array]})
        tiles=({params[tile_array]})
        metatags=({params[metatag_array]})
        for i in `seq 0 $((${{#tiles[@]}} - 1))`; do
            tile=${{tiles[$i]}}
            binsize=${{binsizes[$i]}}
            metatag=${{metatags[$i]}}
            echo "Averaging bigwig for tile=$tile, binsize=$binsize"
            echo "bigWigAverageOverBed {input.bigwig} $tile {output.tmp2}"
            /usr/bin/time -v bigWigAverageOverBed {input.bigwig} $tile {output.tmp2}
            for q in "${{quantiles[@]}}"; do
                outfile={params.output_pre}.${{binsize}}binsize_${{q}}quantiles.qbed
                echo "q=$q, i=$i, tile=$tile, metatag=$metatag, outfile=$outfile"
                if [ -f {output.tmp1} ]; then rm {output.tmp1}; fi
                {params.script} $q {params.min_coverage} $tile {output.tmp2} $outfile \
                    dummy \
                    {output.tmp1} \
                    $metatag
            done
        done > {log} 2>&1
        """
